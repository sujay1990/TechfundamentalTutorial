{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a simple neural network model for XOR operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program creates a neural network that simulates the exclusive OR function with two inputs and one output and 4 hidden layers which will help with the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use numpy for all the computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is a function definition of the sigmoid function,an activation function, which is the type of non-linearity chosen for this neural net.  A sigmoid function maps any value to a value between 0 and 1. We use it to convert numbers to probabilities. \n",
    "The code also performs derivative upon the input if deriv=True. This will be used later in the error back propogation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nonlin(x, deriv=False): \n",
    "    if(deriv==True):\n",
    "        return (x*(1-x))        # returns derivative of input x\n",
    "    \n",
    "    return 1/(1+np.exp(-x))     #returns exponential value of input x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is to create an input matrix. it is a 2x4 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([[0,0],  \n",
    "            [0,1],\n",
    "            [1,0],\n",
    "            [1,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the code below is the output of the XOR function for the input matrix above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.array([[0],\n",
    "             [1],\n",
    "             [1],\n",
    "             [0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers will be randomly distributed in exactly the same way everytime we train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating random weights for synapses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below generates random weight matrix for this neural network. The weights matrix are called synapses.There is 3 layers (input, hidden layer and output). So we need two matrixes(synapses), one before the hidden layer and one after which is connected to the output. The first synapse will be multiplied with the input matrix and then we will run it through the sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matrix is randomly generated in python and is multiplied with the input . Its dimension is (2,4) because we have 2 inputs and 4 hidden layers. l0 is the input and l2 will be the output. l1 will hold the multiplication value of l0 and syn1(input weights) which will then be passed through the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "syn1 = np.random.random((2,4))  # 2x4 matrix of weights ((2 inputs) x 4 nodes in the hidden layer\n",
    "syn2 = np.random.random((4,1))  # 4x1 matrix of weights. (4 nodes x 1 output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "syn2 will be the synapse after the hidden layer. It is of the size 4x1 because we have 4 hidden layers and 1 output. After the sigmoid function is used on l1, l1 will be multiplied with syn1 to generate an output matrix of size 4x1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Main predicition begins below. We will have 60000 iterations, although the number can be increased to get better accuracy, we will keep it at 60000 to get faster results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained above l0 contains the input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l1 contains the multiplication of syn1 with the input which is then passed through the activation function (sigmoid fucntion). There, the activation function is applied to each element of the matrix resulted from l0*syn1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l2 will have product of l1 and syn2 (weights after the hidden layer) which will be again passed through the activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model should look something like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcAAAAFqCAIAAAACwB2sAAAAAXNSR0IArs4c6QAAAARnQU1BAACx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\nABgIBAoAAAOBQAEAYBBJ8v/hkYd3UWkNYwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"F:/Tech fundamentals/Project/Submittals/NN.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Propogation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we first calculate the cost(error). Cost is the difference in the predicted value and the actual output value. Our job here is to minimize the cost function. We can only do that by changing the value of the weights in the synapses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to know how much do the weights in the synapses affect the cost and in which direction. Do they increase or decrease the error. For that we will need the derivative function. If the derivative of the output is positive, then the cost is going up(positive slope) and if the derivative is negative, then the cost is going down(negative slope). This process is called Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to find out the change in error to the change in weights. (this is the chain rule of derivation where you take the outer derivative and multiply it with the inner derivative). because of this, we will take the derivative of the output and multiply this with the error to form a new matrix called l2_delta. This is where we are training the model to make better predictions.\n",
    "We will update syn2 with l2_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we multiply the back propogating error with the Transpose of the activity in each synapse (synapses 2). We will treat this as l1_error. This is to update our synapses 1. We take the derivate of the input of the hidden layer(l1) and multiply it with l1_error to get l1_delta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually, we will update both the synapses , syn1 with product of l0 transpose and l1_delta and syn2 with product of l1 transpose and l2_delta. This will be done for 60000 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.499319690739\n",
      "Error: 0.0165638769582\n",
      "Error: 0.0104669481327\n",
      "Error: 0.008303911676\n",
      "Error: 0.00711919097558\n",
      "Error: 0.00634201641317\n",
      "Output after training\n",
      "[[ 0.00554722]\n",
      " [ 0.99404972]\n",
      " [ 0.99420492]\n",
      " [ 0.0058294 ]]\n"
     ]
    }
   ],
   "source": [
    "for j in range(60000):  \n",
    "    \n",
    "    # Calculate forward through the network.\n",
    "    l0 = X\n",
    "    l1 = nonlin(np.dot(l0, syn1))\n",
    "    l2 = nonlin(np.dot(l1, syn2))\n",
    "    \n",
    "    # Back propagation of errors using the chain rule. \n",
    "    l2_error = y - l2\n",
    "    if(j % 10000) == 0:   # Only print the error every 10000 steps, to save time and limit the amount of output. \n",
    "        print (\"Error: \" + str(np.mean(np.abs(l2_error))))\n",
    "        \n",
    "    l2_delta = l2_error*nonlin(l2, deriv=True)    # back propogating error\n",
    "    \n",
    "    l1_error = l2_delta.dot(syn2.T)\n",
    "    \n",
    "    l1_delta = l1_error * nonlin(l1,deriv=True)\n",
    "    \n",
    "    #update weights\n",
    "    syn2 += l1.T.dot(l2_delta)\n",
    "    syn1 += l0.T.dot(l1_delta)\n",
    "    \n",
    "print (\"Output after training\")\n",
    "print (l2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the output, We can clearly see that at the beginning the error is a lot, but once it starts to train the model over further iterations, the error reduces. The final output after training is very close to the original output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sources : Sirajology simple neural network , lumiverse.io/video , "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
